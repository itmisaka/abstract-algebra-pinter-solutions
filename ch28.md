---
title: Abstract Algebra by Pinter, Chapter 28
author: Amir Taaki
header-includes: |
    - \usepackage{mathrsfs}
    - \usepackage{mathtools}
    - \usepackage{extpfeil}
    - \DeclareMathOperator\ker{ker}
    - \DeclareMathOperator\ord{ord}
    - \DeclareMathOperator\gcd{gcd}
    - \DeclareMathOperator\lcm{lcm}
    - \DeclareMathOperator\char{char}
    - \DeclareMathOperator\max{max}
    - \DeclareMathOperator\ran{ran}
    - \DeclareMathOperator\deg{deg}
    - \DeclareMathOperator\dim{dim}
    - \newcommand{\mod}[1]{\ (\mathrm{mod}\ #1)}
    - \newcommand{\repr}[1]{\overline{#1}}
    - \newcommand{\leg}[2]{\left(\frac{#1}{#2}\right)}
    - \let\vec\mathbf
abstract: Chapter 28 on Vector Spaces
---

# A. Examples of Vector Spaces

## Q1

$$\vec a = (a_1, \dots, a_n), \vec b = (b_1, \dots, b_n)$$
$$\vec a + \vec b = (a_1, \dots, a_n) + (b_1, \dots, b_n) = (a_1 + b_1, \dots, a_n + b_n)$$
$$k \vec a = k(a_1, \dots, a_n) = (ka_1, \dots, ka_n)$$

\begin{align*}
k(\vec a + \vec b) &= k[(a_1, \dots, a_n) + (b_1, \dots, b_n)] \\
&= k(a_1 + b_1, \dots, a_n + b_n) \\
&= (ka_1 + kb_1, \dots, ka_n + kb_n) \\
&= (ka_1, \dots, ka_n) + (kb_1, \dots, kb_n) \\
&= k \vec a + k \vec b
\end{align*}

\begin{align*}
(k + l)\vec a &= ((k + l)a_1, \dots, (k + l)a_n) \\
&= (ka_1 + la_1, \dots, ka_n + la_n) \\
&= (ka_1, \dots, ka_n) + (la_1, \dots, la_n) \\
&= k \vec a + l \vec b
\end{align*}

\begin{align*}
k(l \vec a) &= k(la_1, \dots, la_n) = (kla_1, \dots, kla_n) \\
&= (kl)\vec a
\end{align*}

$$1 \vec a = \vec a$$

## Q2

$$[f + g](x) = f(x) + g(x)$$
$$[af](x) = af(x)$$

All the vector space rules are obeyed.

## Q3

$\mathcal{Pl}$ is trivially easy to show it obeys the vector space rules.

## Q4

Same for $\mathcal{M}_2(\mathbb{R})$.

# B. Exmples of Subspaces

## Q1

$U = \{(a, b, c) : 2a - 3b + c = 0 \}$ and let $\vec u = (a_1, b_1, c_1), \vec v = (a_2, b_2, c_2) \in U$, then $\vec u + \vec v \implies 2a_1 - 3b_1 + c_1 = 2a_2 - 3b_2 + c_2 = 0 \implies 2(a_1 + b_1) - 3(b_1 + b_2) + (c_1 + c_2) = 0 \implies (\vec u + \vec v) \in U$. Also $k\vec v = (ka, kb, kc)$ and $2ka - 3kb + kc = 0 \implies k \vec v \in U$.

## Q2

Let $\vec u, \vec v \in U$, then $\vec u + \vec v$ satisfies the conditions, and hence is also in $U$. Thus $U$ is a closed subspace.

## Q3

For any two functions in $\mathcal{F}(\mathbb{R})$, then $f(1) = 0, g(1) = 0 \implies (f + g)(1) = 0$.

## Q4

Two functions which are constant on the interval $[0, 1]$ when summed will still be constant, hence it is a closed subspace.

## Q5

$f(x) = f(-x), g(x) = g(-x) \implies (f + g)(x) = (f + g)(-x)$. Likewise for odd functions.

## Q6

$f(x) = a_0 x + \cdots + a_n x^n, g(x) = b_0 + \cdots + b_n x^n, f(x) + g(x) = (a_0 + b_0) + \cdots + (a_n + b_n) x^n$.

# C. Examples of Linear Independence and Bases

## Q1

$$
\begin{pmatrix}
   0 \\
   0 \\
   0 \\
   1
 \end{pmatrix}
 =
 k
\begin{pmatrix}
   0 \\
   0 \\
   1 \\
   1
 \end{pmatrix} +
 l
\begin{pmatrix}
   0 \\
   1 \\
   1 \\
   1
 \end{pmatrix} +
 m
\begin{pmatrix}
   1 \\
   1 \\
   1 \\
   1
 \end{pmatrix}$$

$$0 = k \cdot 0 + l \cdot 0 + m \cdot 1 = m \cdot 1$$
$$\implies m = 0$$
$$0 = k \cdot 0 + l \cdot 1 + m \cdot 1 = l \cdot 1$$
$$\implies l = 0$$
$$0 = k \cdot 1 + l \cdot 1 + m \cdot 1 = k \cdot 1$$
$$\implies k = 0$$
\begin{align*}
1 &= k \cdot 1 + l \cdot 1 + m \cdot 1 \\
  &= 0 \cdot 1 + 0 \cdot 1 + 0 \cdot 1 \\
  &= 0 \neq 1
\end{align*}
Contradiction.

## Q2

$a \neq kb$, they are linearly independent. With $c = (0, 1, 0, 0)$ and $d = (0, 0, 1, 0)$ and the vectors, then any element of $\mathbb{R}^4$ can be represented.

## Q3

$$(1, 0, 0) = (2, 1, 1) - (1, 1, 1)$$
$$(0, 1, 0) = (1, 2, 1) - (1, 1, 1)$$
$$(0, 0, 1) = (1, 1, 2) - (1, 1, 1)$$

Every vector of $\mathbb{R}$ is a linear combination of these vectors
$$\{(1, 1, 1), (2, 1, 1), (1, 2, 1), (1, 1, 2)\}$$
Since $(1, 1, 1) = \frac{1}{3}[(2, 1, 1) + (1, 2, 1) + (1, 1, 2)]$, so $\{(2, 1, 1), (1, 2, 1), (1, 1, 2)\}$ is a basis of $\mathbb{R}^3$.

## Q4

Any $a(x)$ is a linear combo of elements from $\{1, x, \dots, x^n\}$. Another basis is $\{k, \dots, kx^n\}$.

## Q5

### a.

There are three variables so the third can be calculated from the first two.

Let $x = 1, y = 1$, then $3 - 2 + z = 0$ or $z = -1$, so one value of $S_1$ is $(1, 1, -1)$. Now let $x = 0, y = 1$, then $z = 2$ or $(0, 1, 2)$. Both $(1, 1, -1)$ and $(0, 1, 2)$ are linearly independent. That is for any k
$$k_1(1, 1, -1) + k_2(0, 1, 2) \neq 0$$

$$\forall \vec v = (x, y, z) \in S_1, \exists k_1, k_2 \in \mathbb{R} : \vec v = k_1(1, 1, -1) + k_2(0, 1, 2)$$
$$\iff \left\{
    \begin{array}{ll}
    x = k_1 \\
    y = k_1 + k_2 \\
    z = -k_1 + 2k_2
    \end{array}\right.$$

For each choice of $k_1, k_2$ above, the equations always have a unique solution.

### b.

$$(x + y - z) + (2x - y + z) = 0$$
$$\implies x = 0$$
$$\implies y = z$$

Basis is therefore $(0, 1, 1)$.

## Q6

According to [this answer](https://math.stackexchange.com/questions/97245/basis-for-the-unit-sphere), it is simply any basis for $\mathbb{R}^3$ such as $(0, 0, 1), (0, 1, 0), (1, 0, 0)$.

## Q7

$$\cos 2x = \cos^2 x - \sin^2 x$$
Thus dimension of $U$ is 2.

Since $U$ is a subspace of $\mathcal{F}(\mathbb{R})$ thus the basis is $(\cos^2 x, \sin^2 x)$.

## Q8

Seems that the given vectors are all independent and cannot be reduced, hence they are also the basis.

# D. Properties of Subspaces and Bases

## Q1

$U$ is a subspace of $V$, then $U$ has a basis the size of $\dim U$. Since the basis consists of vectors from $V$, so the basis of $U$ must have fewer or equal elements to the basis of $V$.
$$\dim U \leq \dim V$$

## Q2

$\dim U = \dim V \implies$ they both have basis of matching length $\implies$ they are basis for the same vector space.

## Q3

$$k_1 \vec a_1 + k_2 \vec a_2 + \cdots + k_n \vec a_n = 0 : k_i \neq 0 \implies k_1 \vec a_1 = -(k_2 \vec a_2 + \cdots + k_n \vec a_n)$$

## Q4

If $\vec a \neq \vec 0$, then $k \vec a = 0 \implies k = 0$.

## Q5

$$\{\vec a_1, \dots, \vec a_n\}, k_1 \vec a_1 + \dots + k_n \vec a_n \neq \vec 0 \implies k_1 \vec a_1 + \dots + k_i \vec a_i \neq \vec 0$$
because otherwise if $k_{i + 1} = \cdots = k_n = 0$, then not all $k$ in $k_1 \vec a_1 + \cdots + k_n \vec a_n$ are zero yet it equals $\vec 0$. So any subset of an independent set is also independent.

A set of dependent vectors still remains dependent when contained in a larger set because
$$k_1 \vec a_1 + \cdots + k_n \vec a_n + 0 b_1 + \cdots + 0 b_n = \vec 0$$

## Q6

$$k(\vec a + \vec b) + l(\vec b + \vec c) + m(\vec a + \vec c) = \vec 0$$
$$k \vec a + k \vec b + l \vec b + l \vec c + m \vec a + m \vec c = \vec 0$$
$$(k + m)\vec a + (k + l) \vec b + (l + m) \vec c = \vec 0$$
$$\implies k + m = k + l = l + m = 0$$
So $\{\vec a + \vec b, \vec b + \vec c, \vec a + \vec c\}$ is linearly independent as well.

## Q7

Both have the same number of elements so we just need to show that it is linearly independent to prove it's a basis of $V$.

$\{\vec a_1, \dots, \vec a_n\}$ is a basis and so is linearly independent. Thus multiply the elements by $k$, they remain linearly independent.

## Q8

$V$ is spanned by $\{\vec a_1, \dots, \vec a_n \}$ so every vector in $V$ including $\{ \vec b_1, \dots, \vec b_m \}$ is a linear combo of $\{ \vec a_1, \dots, \vec a_n \}$. Argument also works both ways.

# E. Properties of Linear Transformations

## Q1

$$\vec a, \vec b \in U : h(\vec a) = h(\vec b) = \vec 0 \implies \vec a, \vec b \in \ker h$$
$$\implies h(\vec a) + h(\vec b) = \vec 0 = h(\vec a + \vec b)$$
$$\implies \vec a + \vec b \in \ker h$$
so $\ker h$ is a subspace of $U$.

## Q2

$$k_a h(\vec a) + k_b h(\vec b) = h(k_a \vec a + k_b \vec b) \in \ran h$$

## Q3

$\ker h = \{ \vec 0 \} \implies h(\vec a) = \vec 0$ then $a = \vec 0 \implies h(\vec a) = h(\vec b) = \vec 0$ then $\vec a = \vec b$ and so $h$ is injective.

Likewise if $h$ is injective then $h(\vec a) = h(\vec 0) \implies \vec a = 0$, thus $\ker h = \{ \vec 0 \}$.

## Q4

$$\vec a \in \mathcal{N} \implies \vec a = k_1 \vec a_1 + \cdots + k_r \vec a_r$$
$$h(\vec a) = \vec 0 = k_1 h(\vec a_1) + \cdots + k_r h(\vec a_r)$$

$$b \in U \implies \vec b = k_1 \vec a_1 + \cdots + k_r \vec a_r + k_{r + 1} \vec a_{r + 1} + \cdots + k_n \vec a_n$$
\begin{align*}
\implies h(\vec b) &= (k_1 h(\vec a_1) + \cdots + k_r h(\vec a_r)) + k_{r + 1} h(\vec a_{r + 1}) + \cdots + k_n h(\vec a_n) \\
&= \vec 0 + k_{r + 1} h(\vec a_{r + 1}) + \cdots + k_n h(\vec a_n)
\end{align*}

## Q5

If $\{ h(\vec a_{r+1}), \dots, h(\vec a_n) \}$ is linearly independent, then $k_{r + 1} h(\vec a_{r + 1}) + \cdots + k_n h(\vec a_n) = \vec 0 \implies k_{r + 1} = \cdots = k_n$.

If the vector is dependent, then there is a combination of the vectors that equals $\vec 0$ and so they are part of the null space.

## Q6

The vectors from $r+1$ to $n$ are linearly independent, and span $\mathcal{R}$, so they are also a basis. Since they are a basis, the number of vectors is $n - r$ and this is also the dimension of $\mathcal{R} = \ran h$.

## Q7

Null space of $h$ is $r$ and $ran h$ is $n - r$, so total is $n$, which is the domain of $h$.

## Q8

If $h$ is injective, then every element of $U$ maps to a single element of $V$. Thus the codomain dimension is higher or equal to the domain's. They are equal so therefore $h$ is surjective.

Likewise if $h$ is surjective, then every element contains a preimage in the domain. The value $\vec 0 \in V$ has a single preimage so the nullspace is $\{ \vec 0 \}$ and the range of $h$ is $n - 1$. Thus the domain dimension is $n$, and so the function is injective since domain and codomain are equal.

# F. Isomorphism of Vector Spaces

## Q1

$$k_1 h(\vec a_1) + \cdots + k_r h(\vec a_r) = \vec 0 = h(k_1 \vec a_1 + \cdots + k_r \vec a_r)$$
since $h$ is injective, then the null space is $\{ \vec 0 \}$.
$$k_1 \vec a_1 + \cdots + k_r \vec a_r = \vec 0$$
but $\{\vec a_1, \dots, \vec a_r\}$ is linearly dependent so
$$k_1 = \cdots = k_r = 0$$
so $\{h(\vec a_1, \dots, h(\vec a_r)\}$ is linearly independent.

## Q2

Looking from google the dimension of a null space which is $\{ \vec 0 \}$ is 0 since it has no basis.

From 28E7
\begin{align*}
\dim U &= \dim \mathcal{N} + \dim {(\ran h)} \\
&= 0 + (r - 0) \\
&= r
\end{align*}
since $h$ is injective and $\dim {(\ran h)} = r$.

Likewise if the range of $h$ is $r = \dim U$, then the kernel of $h$ is a single element and the quotient group has the same structure as $U$.

## Q3

Either $h$ maps to $\{ \vec 0 \}$ or $h$ is isomorphic.

If $h$ is injective (every image of $h$ has a single preimage) or surjective (every element of $V$ has a preimage for $h$), then because $\dim U = \dim V$, then $h$ is an isomorphism.

## Q4

$$V = \{ k_1 \vec a_1 + \cdots + k_n \vec a_n : k_i \in F \}$$
where $\{ a_1, \dots, a_n \}$ is the basis of $V$. Which is all the possible n-dimensional vectors over $F$.
$$V \cong F^n$$

# G. Sums of Vector Spaces

## Q1

$T + U$ and $T \cap U$ are closed with respect to addition and scalar multiplication.

Let $\vec a \in T \cap U$, $k \in F$, then
$$k \vec a \in T, k \vec a \in U$$

## Q2

For every $\vec c \in V, \vec c = \vec a + \vec b : \vec a \in T, \vec b \in U \implies V = T + U$.

Since $\vec c$ is uniquely expressible in terms of $\vec a$ and $\vec b$ then this means $T \cap U = \{ \vec 0 \}$.

This works both ways. If every element of $V$ is expressed as $T + U$ and $T \cap U = \{ \vec 0 \}$ then every element $\vec c = \vec a + \vec b$.

## Q3

$T$ has a basis $T = (\vec t_1, \dots, \vec t_k)$ and since $T$ is a subspace of $V$, this can be extended to $V = (\vec t_1, \dots, \vec t_k, \vec u_1, \dots, \vec u_{n - k})$. It is easily seen that $(\vec u_1, \dots, \vec u_{n - k})$ forms an independent basis and so
\begin{align*}
\vec v &= a_1 \vec t_1 + \cdots + a_k \vec t_k + b_1 \vec u_1 + \cdots + b_{n - k} \vec u_{n - k} \\
&= (a_1 \vec t_1 + \cdots + a_k \vec t_k) + (b_1 \vec u_1 + \cdots + b_{n - k} \vec u_{n - k}) \\
\end{align*}
$$\implies \vec v = \vec t' + \vec u'$$

## Q4

$$T = T \cap U + T \cap U^c$$
$$U = T \cap U + U \cap T^c$$
$$T + U = T \cap U + T \cap U^c + U \cap T^c$$

$$\dim T = \dim (T \cap U) + \dim(T \cap U^c)$$
$$\dim U = \dim (T \cap U) + \dim(U \cap T^c)$$
\begin{align*}
\dim (T + U) &= \dim (T \cap U) + (\dim T - \dim(T \cap U)) + (\dim U - \dim (T \cap U)) \\
&= \dim T + \dim U - \dim (T \cap U)
\end{align*}

